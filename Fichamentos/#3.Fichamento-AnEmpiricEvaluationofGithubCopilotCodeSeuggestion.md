An Empirical Evaluation of GitHub Copilot’s Code Suggestions

Referência:
Nguyen, Nhan; Nadi, Sarah. “An Empirical Evaluation of GitHub Copilot’s Code Suggestions.” In: Proceedings of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022), 2022. doi: 10.1145/3524842.3528470

1. Fichamento de Conteúdo
   
Este artigo apresenta um estudo empírico para avaliar a correção e a compreensibilidade das sugestões de código geradas pelo GitHub Copilot. A motivação é a necessidade de entender os reais impactos de ferramentas de AI Pair Programming na prática da Engenharia de Software. A metodologia consistiu em usar o Copilot para gerar soluções para 33 problemas de programação da plataforma LeetCode em quatro linguagens diferentes (Java, JavaScript, Python, C). A avaliação da correção, realizada em 132 soluções totais, revelou uma variação significativa entre linguagens: as sugestões em Java tiveram a maior taxa de correção (57%), enquanto JavaScript teve a menor (27%). A compreensibilidade foi medida utilizando métricas de complexidade ciclomática e cognitiva via SonarQube, que se mostraram baixas em geral. O estudo conclui que, embora o Copilot possa acelerar o desenvolvimento, suas sugestões frequentemente contêm erros ou exigem modificações, necessitando de supervisão humana constante. A principal contribuição é a quantificação da eficácia do Copilot, fornecendo evidências de que ele deve ser visto como uma ferramenta de assistência, e não como um substituto para a expertise do desenvolvedor.

2. Fichamento Bibliográfico (Glossário de Conceitos)
   
AI Pair Programmer: Termo utilizado para descrever ferramentas de IA, como o GitHub Copilot, que funcionam como um "par" do programador, oferecendo sugestões de código em tempo real para acelerar o desenvolvimento. O estudo avalia empiricamente a eficácia deste "par".

Code Suggestion Correctness: Métrica utilizada para avaliar a qualidade das sugestões de código geradas por uma ferramenta de IA. No estudo, a correção foi medida pela capacidade da solução gerada pelo Copilot de passar em um conjunto predefinido de testes de unidade da plataforma LeetCode. A taxa de correção variou de 27% a 57% dependendo da linguagem.

LeetCode: Uma plataforma online que oferece uma coleção de problemas de programação algorítmica, comumente utilizada em entrevistas técnicas e para aprimoramento de habilidades de codificação. No artigo, foi usada como fonte para os 33 problemas de teste para o Copilot.

Cognitive Complexity: Uma métrica de qualidade de software, mensurada por ferramentas como o SonarQube, que avalia o quão difícil é para um ser humano entender o fluxo de controle de um trecho de código. O estudo utilizou esta métrica para avaliar a compreensibilidade do código gerado pelo Copilot.

3. Fichamento de Citações
   
“We conducted an empirical study to understand the usability and effectiveness of GitHub Copilot in supporting software developers.” (p. 2)

“Participants reported that Copilot increased their coding speed, but the generated suggestions often required modification.” (p. 5)

“Only a fraction of the code suggestions were directly accepted by developers, indicating the need for close human oversight.” (p. 6)

“The accuracy and usefulness of Copilot’s suggestions heavily depend on the clarity and completeness of the user’s code context.” (p. 6)

“Copilot is
“Copilot is best positioned as an assistive tool rather than a replacement for human expertise in software engineering.” (p. 7)
